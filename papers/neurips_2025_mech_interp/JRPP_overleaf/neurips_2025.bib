@misc{arditi2024refusallanguagemodelsmediated,
      title={Refusal in Language Models Is Mediated by a Single Direction}, 
      author={Andy Arditi and Oscar Obeso and Aaquib Syed and Daniel Paleka and Nina Panickssery and Wes Gurnee and Neel Nanda},
      year={2024},
      eprint={2406.11717},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2406.11717}, 
}

@misc{zou2023universaltransferableadversarialattacks,
      title={Universal and Transferable Adversarial Attacks on Aligned Language Models}, 
      author={Andy Zou and Zifan Wang and Nicholas Carlini and Milad Nasr and J. Zico Kolter and Matt Fredrikson},
      year={2023},
      eprint={2307.15043},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2307.15043}, 
}

@misc{yeo2025understandingrefusallanguagemodels,
      title={Understanding Refusal in Language Models with Sparse Autoencoders}, 
      author={Wei Jie Yeo and Nirmalendu Prakash and Clement Neo and Roy Ka-Wei Lee and Erik Cambria and Ranjan Satapathy},
      year={2025},
      eprint={2505.23556},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2505.23556}, 
}

@misc{touvron2023llama2openfoundation,
      title={Llama 2: Open Foundation and Fine-Tuned Chat Models}, 
      author={Hugo Touvron and Louis Martin and Kevin Stone and Peter Albert and Amjad Almahairi and Yasmine Babaei and Nikolay Bashlykov and Soumya Batra and Prajjwal Bhargava and Shruti Bhosale and Dan Bikel and Lukas Blecher and Cristian Canton Ferrer and Moya Chen and Guillem Cucurull and David Esiobu and Jude Fernandes and Jeremy Fu and Wenyin Fu and Brian Fuller and Cynthia Gao and Vedanuj Goswami and Naman Goyal and Anthony Hartshorn and Saghar Hosseini and Rui Hou and Hakan Inan and Marcin Kardas and Viktor Kerkez and Madian Khabsa and Isabel Kloumann and Artem Korenev and Punit Singh Koura and Marie-Anne Lachaux and Thibaut Lavril and Jenya Lee and Diana Liskovich and Yinghai Lu and Yuning Mao and Xavier Martinet and Todor Mihaylov and Pushkar Mishra and Igor Molybog and Yixin Nie and Andrew Poulton and Jeremy Reizenstein and Rashi Rungta and Kalyan Saladi and Alan Schelten and Ruan Silva and Eric Michael Smith and Ranjan Subramanian and Xiaoqing Ellen Tan and Binh Tang and Ross Taylor and Adina Williams and Jian Xiang Kuan and Puxin Xu and Zheng Yan and Iliyan Zarov and Yuchen Zhang and Angela Fan and Melanie Kambadur and Sharan Narang and Aurelien Rodriguez and Robert Stojnic and Sergey Edunov and Thomas Scialom},
      year={2023},
      eprint={2307.09288},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2307.09288}, 
}

@misc{ma2025safetyscalecomprehensivesurvey,
      title={Safety at Scale: A Comprehensive Survey of Large Model and Agent Safety}, 
      author={Xingjun Ma and Yifeng Gao and Yixu Wang and Ruofan Wang and Xin Wang and Ye Sun and Yifan Ding and Hengyuan Xu and Yunhao Chen and Yunhan Zhao and Hanxun Huang and Yige Li and Yutao Wu and Jiaming Zhang and Xiang Zheng and Yang Bai and Zuxuan Wu and Xipeng Qiu and Jingfeng Zhang and Yiming Li and Xudong Han and Haonan Li and Jun Sun and Cong Wang and Jindong Gu and Baoyuan Wu and Siheng Chen and Tianwei Zhang and Yang Liu and Mingming Gong and Tongliang Liu and Shirui Pan and Cihang Xie and Tianyu Pang and Yinpeng Dong and Ruoxi Jia and Yang Zhang and Shiqing Ma and Xiangyu Zhang and Neil Gong and Chaowei Xiao and Sarah Erfani and Tim Baldwin and Bo Li and Masashi Sugiyama and Dacheng Tao and James Bailey and Yu-Gang Jiang},
      year={2025},
      eprint={2502.05206},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2502.05206}, 
}

@misc{jiang2024wildteamingscaleinthewildjailbreaks,
      title={WildTeaming at Scale: From In-the-Wild Jailbreaks to (Adversarially) Safer Language Models}, 
      author={Liwei Jiang and Kavel Rao and Seungju Han and Allyson Ettinger and Faeze Brahman and Sachin Kumar and Niloofar Mireshghallah and Ximing Lu and Maarten Sap and Yejin Choi and Nouha Dziri},
      year={2024},
      eprint={2406.18510},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.18510}, 
}

@misc{cui2025orbenchoverrefusalbenchmarklarge,
      title={OR-Bench: An Over-Refusal Benchmark for Large Language Models}, 
      author={Justin Cui and Wei-Lin Chiang and Ion Stoica and Cho-Jui Hsieh},
      year={2025},
      eprint={2405.20947},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2405.20947}, 
}

@misc{vonrecum2024notautomaticanalysisrefusal,
      title={Cannot or Should Not? Automatic Analysis of Refusal Composition in IFT/RLHF Datasets and Refusal Behavior of Black-Box LLMs}, 
      author={Alexander von Recum and Christoph Schnabl and Gabor Hollbeck and Silas Alberti and Philip Blinde and Marvin von Hagen},
      year={2024},
      eprint={2412.16974},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2412.16974}, 
}

@misc{ouyang2022traininglanguagemodelsfollow,
      title={Training language models to follow instructions with human feedback}, 
      author={Long Ouyang and Jeff Wu and Xu Jiang and Diogo Almeida and Carroll L. Wainwright and Pamela Mishkin and Chong Zhang and Sandhini Agarwal and Katarina Slama and Alex Ray and John Schulman and Jacob Hilton and Fraser Kelton and Luke Miller and Maddie Simens and Amanda Askell and Peter Welinder and Paul Christiano and Jan Leike and Ryan Lowe},
      year={2022},
      eprint={2203.02155},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2203.02155}, 
}

@misc{bai2022constitutionalaiharmlessnessai,
      title={Constitutional AI: Harmlessness from AI Feedback}, 
      author={Yuntao Bai and Saurav Kadavath and Sandipan Kundu and Amanda Askell and Jackson Kernion and Andy Jones and Anna Chen and Anna Goldie and Azalia Mirhoseini and Cameron McKinnon and Carol Chen and Catherine Olsson and Christopher Olah and Danny Hernandez and Dawn Drain and Deep Ganguli and Dustin Li and Eli Tran-Johnson and Ethan Perez and Jamie Kerr and Jared Mueller and Jeffrey Ladish and Joshua Landau and Kamal Ndousse and Kamile Lukosuite and Liane Lovitt and Michael Sellitto and Nelson Elhage and Nicholas Schiefer and Noemi Mercado and Nova DasSarma and Robert Lasenby and Robin Larson and Sam Ringer and Scott Johnston and Shauna Kravec and Sheer El Showk and Stanislav Fort and Tamera Lanham and Timothy Telleen-Lawton and Tom Conerly and Tom Henighan and Tristan Hume and Samuel R. Bowman and Zac Hatfield-Dodds and Ben Mann and Dario Amodei and Nicholas Joseph and Sam McCandlish and Tom Brown and Jared Kaplan},
      year={2022},
      eprint={2212.08073},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2212.08073}, 
}

@misc{mazeika2024harmbenchstandardizedevaluationframework,
      title={HarmBench: A Standardized Evaluation Framework for Automated Red Teaming and Robust Refusal}, 
      author={Mantas Mazeika and Long Phan and Xuwang Yin and Andy Zou and Zifan Wang and Norman Mu and Elham Sakhaee and Nathaniel Li and Steven Basart and Bo Li and David Forsyth and Dan Hendrycks},
      year={2024},
      eprint={2402.04249},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2402.04249}, 
}

@misc{pasch2025aivshumanjudgment,
      title={AI vs. Human Judgment of Content Moderation: LLM-as-a-Judge and Ethics-Based Response Refusals}, 
      author={Stefan Pasch},
      year={2025},
      eprint={2505.15365},
      archivePrefix={arXiv},
      primaryClass={cs.HC},
      url={https://arxiv.org/abs/2505.15365}, 
}

@misc{jain2024refusaltokenssimpleway,
      title={Refusal Tokens: A Simple Way to Calibrate Refusals in Large Language Models}, 
      author={Neel Jain and Aditya Shrivastava and Chenyang Zhu and Daben Liu and Alfy Samuel and Ashwinee Panda and Anoop Kumar and Micah Goldblum and Tom Goldstein},
      year={2024},
      eprint={2412.06748},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2412.06748}, 
}

@misc{rai2025practicalreviewmechanisticinterpretability,
      title={A Practical Review of Mechanistic Interpretability for Transformer-Based Language Models}, 
      author={Daking Rai and Yilun Zhou and Shi Feng and Abulhair Saparov and Ziyu Yao},
      year={2025},
      eprint={2407.02646},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2407.02646}, 
}

@misc{vig2020causalmediationanalysisinterpreting,
      title={Causal Mediation Analysis for Interpreting Neural NLP: The Case of Gender Bias}, 
      author={Jesse Vig and Sebastian Gehrmann and Yonatan Belinkov and Sharon Qian and Daniel Nevo and Simas Sakenis and Jason Huang and Yaron Singer and Stuart Shieber},
      year={2020},
      eprint={2004.12265},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2004.12265}, 
}

@misc{zhang2024bestpracticesactivationpatching,
      title={Towards Best Practices of Activation Patching in Language Models: Metrics and Methods}, 
      author={Fred Zhang and Neel Nanda},
      year={2024},
      eprint={2309.16042},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2309.16042}, 
}

@misc{syed2023attributionpatchingoutperformsautomated,
      title={Attribution Patching Outperforms Automated Circuit Discovery}, 
      author={Aaquib Syed and Can Rager and Arthur Conmy},
      year={2023},
      eprint={2310.10348},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2310.10348}, 
}

@misc{kramár2024atpefficientscalablemethod,
      title={AtP*: An efficient and scalable method for localizing LLM behaviour to components}, 
      author={János Kramár and Tom Lieberum and Rohin Shah and Neel Nanda},
      year={2024},
      eprint={2403.00745},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2403.00745}, 
}

@misc{geiger2025causalabstractiontheoreticalfoundation,
      title={Causal Abstraction: A Theoretical Foundation for Mechanistic Interpretability}, 
      author={Atticus Geiger and Duligur Ibeling and Amir Zur and Maheep Chaudhary and Sonakshi Chauhan and Jing Huang and Aryaman Arora and Zhengxuan Wu and Noah Goodman and Christopher Potts and Thomas Icard},
      year={2025},
      eprint={2301.04709},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2301.04709}, 
}

@misc{Elhage_Nanda_2021, title={A Mathematical Framework for Transformer Circuits}, url={https://transformer-circuits.pub/2021/framework/index.html}, journal={Transformer Circuits Thread}, author={Elhage, Nelson and Nanda, Neel}, year={2021}, month={Dec}} 

@misc{subramani2022extractinglatentsteeringvectors,
      title={Extracting Latent Steering Vectors from Pretrained Language Models}, 
      author={Nishant Subramani and Nivedita Suresh and Matthew E. Peters},
      year={2022},
      eprint={2205.05124},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2205.05124}, 
}

@misc{turner2024steeringlanguagemodelsactivation,
      title={Steering Language Models With Activation Engineering}, 
      author={Alexander Matt Turner and Lisa Thiergart and Gavin Leech and David Udell and Juan J. Vazquez and Ulisse Mini and Monte MacDiarmid},
      year={2024},
      eprint={2308.10248},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2308.10248}, 
}

@misc{facchiano2025activationpatchinginterpretablesteering,
      title={Activation Patching for Interpretable Steering in Music Generation}, 
      author={Simone Facchiano and Giorgio Strano and Donato Crisostomi and Irene Tallini and Tommaso Mencattini and Fabio Galasso and Emanuele Rodolà},
      year={2025},
      eprint={2504.04479},
      archivePrefix={arXiv},
      primaryClass={cs.SD},
      url={https://arxiv.org/abs/2504.04479}, 
}

@misc{lee2025programmingrefusalconditionalactivation,
      title={Programming Refusal with Conditional Activation Steering}, 
      author={Bruce W. Lee and Inkit Padhi and Karthikeyan Natesan Ramamurthy and Erik Miehling and Pierre Dognin and Manish Nagireddy and Amit Dhurandhar},
      year={2025},
      eprint={2409.05907},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2409.05907}, 
}

@misc{panickssery2024steeringllama2contrastive,
      title={Steering Llama 2 via Contrastive Activation Addition}, 
      author={Nina Panickssery and Nick Gabrieli and Julian Schulz and Meg Tong and Evan Hubinger and Alexander Matt Turner},
      year={2024},
      eprint={2312.06681},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2312.06681}, 
}

@misc{bayat2025steeringlargelanguagemodel,
      title={Steering Large Language Model Activations in Sparse Spaces}, 
      author={Reza Bayat and Ali Rahimi-Kalahroudi and Mohammad Pezeshki and Sarath Chandar and Pascal Vincent},
      year={2025},
      eprint={2503.00177},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2503.00177}, 
}

@misc{sharma2025understandingsycophancylanguagemodels,
      title={Towards Understanding Sycophancy in Language Models}, 
      author={Mrinank Sharma and Meg Tong and Tomasz Korbak and David Duvenaud and Amanda Askell and Samuel R. Bowman and Newton Cheng and Esin Durmus and Zac Hatfield-Dodds and Scott R. Johnston and Shauna Kravec and Timothy Maxwell and Sam McCandlish and Kamal Ndousse and Oliver Rausch and Nicholas Schiefer and Da Yan and Miranda Zhang and Ethan Perez},
      year={2025},
      eprint={2310.13548},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2310.13548}, 
}

@misc{chaudhary2024evaluatingopensourcesparseautoencoders,
      title={Evaluating Open-Source Sparse Autoencoders on Disentangling Factual Knowledge in GPT-2 Small}, 
      author={Maheep Chaudhary and Atticus Geiger},
      year={2024},
      eprint={2409.04478},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2409.04478}, 
}

@misc{farrell2024applyingsparseautoencodersunlearn,
      title={Applying sparse autoencoders to unlearn knowledge in language models}, 
      author={Eoin Farrell and Yeu-Tong Lau and Arthur Conmy},
      year={2024},
      eprint={2410.19278},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2410.19278}, 
}

@misc{obrien2025steeringlanguagemodelrefusal,
      title={Steering Language Model Refusal with Sparse Autoencoders}, 
      author={Kyle O'Brien and David Majercak and Xavier Fernandes and Richard Edgar and Blake Bullwinkel and Jingya Chen and Harsha Nori and Dean Carignan and Eric Horvitz and Forough Poursabzi-Sangdeh},
      year={2025},
      eprint={2411.11296},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2411.11296}, 
}

@misc{brahman2024artsayingnocontextual,
      title={The Art of Saying No: Contextual Noncompliance in Language Models}, 
      author={Faeze Brahman and Sachin Kumar and Vidhisha Balachandran and Pradeep Dasigi and Valentina Pyatkin and Abhilasha Ravichander and Sarah Wiegreffe and Nouha Dziri and Khyathi Chandu and Jack Hessel and Yulia Tsvetkov and Noah A. Smith and Yejin Choi and Hannaneh Hajishirzi},
      year={2024},
      eprint={2407.12043},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2407.12043}, 
}

@misc{Olah_2020,
    title={Zoom in: An introduction to circuits},
    author={Chris Olah and Nick Cammarata and Ludwig Schubert and Gabriel Goh and Michael Petrov and Shan Carter},
    url={https://distill.pub/2020/circuits/zoom-in/},
    journal={Distill},
    year={2020}} 

@misc{conmy2023automatedcircuitdiscoverymechanistic,
      title={Towards Automated Circuit Discovery for Mechanistic Interpretability}, 
      author={Arthur Conmy and Augustine N. Mavor-Parker and Aengus Lynch and Stefan Heimersheim and Adrià Garriga-Alonso},
      year={2023},
      eprint={2304.14997},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2304.14997}, 
}

@inproceedings{geva-etal-2022-transformer,
    title = "Transformer Feed-Forward Layers Build Predictions by Promoting Concepts in the Vocabulary Space",
    author = "Geva, Mor  and
      Caciularu, Avi  and
      Wang, Kevin  and
      Goldberg, Yoav",
    editor = "Goldberg, Yoav  and
      Kozareva, Zornitsa  and
      Zhang, Yue",
    booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.emnlp-main.3/",
    doi = "10.18653/v1/2022.emnlp-main.3",
    pages = "30--45",
    abstract = "Transformer-based language models (LMs) are at the core of modern NLP, but their internal prediction construction process is opaque and largely not understood. In this work, we make a substantial step towards unveiling this underlying prediction process, by reverse-engineering the operation of the feed-forward network (FFN) layers, one of the building blocks of transformer models. We view the token representation as a changing distribution over the vocabulary, and the output from each FFN layer as an additive update to that distribution. Then, we analyze the FFN updates in the vocabulary space, showing that each update can be decomposed to sub-updates corresponding to single FFN parameter vectors, each promoting concepts that are often human-interpretable. We then leverage these findings for controlling LM predictions, where we reduce the toxicity of GPT2 by almost 50{\%}, and for improving computation efficiency with a simple early exit rule, saving 20{\%} of computation on average."
}

@misc{meyes2019ablationstudiesartificialneural,
      title={Ablation Studies in Artificial Neural Networks}, 
      author={Richard Meyes and Melanie Lu and Constantin Waubert de Puiseau and Tobias Meisen},
      year={2019},
      eprint={1901.08644},
      archivePrefix={arXiv},
      primaryClass={cs.NE},
      url={https://arxiv.org/abs/1901.08644}, 
}

@misc{li2017understandingneuralnetworksrepresentation,
      title={Understanding Neural Networks through Representation Erasure}, 
      author={Jiwei Li and Will Monroe and Dan Jurafsky},
      year={2017},
      eprint={1612.08220},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1612.08220}, 
}

@misc{michel2019sixteenheadsreallybetter,
      title={Are Sixteen Heads Really Better than One?}, 
      author={Paul Michel and Omer Levy and Graham Neubig},
      year={2019},
      eprint={1905.10650},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1905.10650}, 
}

@misc{zhou2018revisitingimportanceindividualunits,
      title={Revisiting the Importance of Individual Units in CNNs via Ablation}, 
      author={Bolei Zhou and Yiyou Sun and David Bau and Antonio Torralba},
      year={2018},
      eprint={1806.02891},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1806.02891}, 
}

@misc{cobbe2021trainingverifierssolvemath,
      title={Training Verifiers to Solve Math Word Problems}, 
      author={Karl Cobbe and Vineet Kosaraju and Mohammad Bavarian and Mark Chen and Heewoo Jun and Lukasz Kaiser and Matthias Plappert and Jerry Tworek and Jacob Hilton and Reiichiro Nakano and Christopher Hesse and John Schulman},
      year={2021},
      eprint={2110.14168},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2110.14168}, 
}

@misc{hendrycks2021measuringmassivemultitasklanguage,
      title={Measuring Massive Multitask Language Understanding}, 
      author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},
      year={2021},
      eprint={2009.03300},
      archivePrefix={arXiv},
      primaryClass={cs.CY},
      url={https://arxiv.org/abs/2009.03300}, 
}

@misc{lin2022truthfulqameasuringmodelsmimic,
      title={TruthfulQA: Measuring How Models Mimic Human Falsehoods}, 
      author={Stephanie Lin and Jacob Hilton and Owain Evans},
      year={2022},
      eprint={2109.07958},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2109.07958}, 
}

@misc{comanici2025gemini25pushingfrontier,
      title={Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities}, 
      author={Google DeepMind},
      year={2025},
      eprint={2507.06261},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2507.06261}, 
}